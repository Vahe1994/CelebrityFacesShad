{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks for Face AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imageio import imread\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from glob import glob\n",
    "import numpy as npCan't get attribute\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human HT29 colon-cancer cells\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(1,2,1)\n",
    "im = imread('./face_image/000001.jpg')\n",
    "plt.imshow(im)\n",
    "plt.subplot(1,2,2)\n",
    "mask = imread('./face_image/000005.jpg')\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('./face_image/000001.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.resize((128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archiecture from here https://github.com/bhpfelix/Variational-Autoencoder-PyTorch\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, nc, ngf, ndf, latent_variable_size):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.nc = nc\n",
    "        self.ngf = ngf\n",
    "        self.ndf = ndf\n",
    "        self.latent_variable_size = latent_variable_size\n",
    "\n",
    "        # encoder\n",
    "        self.e1 = nn.Conv2d(nc, ndf, 4, 2, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(ndf)\n",
    "\n",
    "        self.e2 = nn.Conv2d(ndf, ndf*2, 4, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(ndf*2)\n",
    "\n",
    "        self.e3 = nn.Conv2d(ndf*2, ndf*4, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(ndf*4)\n",
    "\n",
    "        self.e4 = nn.Conv2d(ndf*4, ndf*8, 4, 2, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(ndf*8)\n",
    "\n",
    "        self.e5 = nn.Conv2d(ndf*8, ndf*8, 4, 2, 1)\n",
    "        self.bn5 = nn.BatchNorm2d(ndf*8)\n",
    "\n",
    "        self.fc1 = nn.Linear(ndf*8*4*4, latent_variable_size)\n",
    "        self.fc2 = nn.Linear(ndf*8*4*4, latent_variable_size)\n",
    "\n",
    "        # decoder\n",
    "        self.d1 = nn.Linear(latent_variable_size, ngf*8*2*4*4)\n",
    "\n",
    "        self.up1 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd1 = nn.ReplicationPad2d(1)\n",
    "        self.d2 = nn.Conv2d(ngf*8*2, ngf*8, 3, 1)\n",
    "        self.bn6 = nn.BatchNorm2d(ngf*8, 1.e-3)\n",
    "\n",
    "        self.up2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd2 = nn.ReplicationPad2d(1)\n",
    "        self.d3 = nn.Conv2d(ngf*8, ngf*4, 3, 1)\n",
    "        self.bn7 = nn.BatchNorm2d(ngf*4, 1.e-3)\n",
    "\n",
    "        self.up3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd3 = nn.ReplicationPad2d(1)\n",
    "        self.d4 = nn.Conv2d(ngf*4, ngf*2, 3, 1)\n",
    "        self.bn8 = nn.BatchNorm2d(ngf*2, 1.e-3)\n",
    "\n",
    "        self.up4 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd4 = nn.ReplicationPad2d(1)\n",
    "        self.d5 = nn.Conv2d(ngf*2, ngf, 3, 1)\n",
    "        self.bn9 = nn.BatchNorm2d(ngf, 1.e-3)\n",
    "\n",
    "        self.up5 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd5 = nn.ReplicationPad2d(1)\n",
    "        self.d6 = nn.Conv2d(ngf, nc, 3, 1)\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.leakyrelu(self.bn1(self.e1(x)))\n",
    "        h2 = self.leakyrelu(self.bn2(self.e2(h1)))\n",
    "        h3 = self.leakyrelu(self.bn3(self.e3(h2)))\n",
    "        h4 = self.leakyrelu(self.bn4(self.e4(h3)))\n",
    "        h5 = self.leakyrelu(self.bn5(self.e5(h4)))\n",
    "        h5 = h5.view(-1, self.ndf*8*4*4)\n",
    "\n",
    "        return self.fc1(h5), self.fc2(h5)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if args.cuda:\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h1 = self.relu(self.d1(z))\n",
    "        h1 = h1.view(-1, self.ngf*8*2, 4, 4)\n",
    "        h2 = self.leakyrelu(self.bn6(self.d2(self.pd1(self.up1(h1)))))\n",
    "        h3 = self.leakyrelu(self.bn7(self.d3(self.pd2(self.up2(h2)))))\n",
    "        h4 = self.leakyrelu(self.bn8(self.d4(self.pd3(self.up3(h3)))))\n",
    "        h5 = self.leakyrelu(self.bn9(self.d5(self.pd4(self.up4(h4)))))\n",
    "\n",
    "        return self.sigmoid(self.d6(self.pd5(self.up5(h5))))\n",
    "\n",
    "    def get_latent_var(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        res = self.decode(z)\n",
    "        return res, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(nc=3, ngf=128, ndf=128, latent_variable_size=128).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=torch.load('model')\n",
    "totensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim as opt\n",
    "reconstruction_function = nn.BCELoss()\n",
    "reconstruction_function.size_average = False\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = reconstruction_function(recon_x, x)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "optimizer = opt.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "args = Object()\n",
    "args.cuda = True\n",
    "args.log_interval=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import np # Torch wrapper for Numpy\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "a=0\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "class MakeData(Dataset):\n",
    "    def __init__(self,  img_path,img_y_path, transform=None,tr=None):\n",
    "        \n",
    "        tmp_df_x = os.listdir(img_path)\n",
    "        tmp_df_x.sort()\n",
    "        \n",
    "        tmp_df_y = os.listdir(img_y_path)\n",
    "        tmp_df_y.sort()\n",
    "        \n",
    "        self.img_path_x = img_path\n",
    "        self.img_path_y = img_y_path\n",
    "        self.transform = transform\n",
    "        self.tr =tr\n",
    "        self.X_train = tmp_df_x\n",
    "        self.y_train = tmp_df_y\n",
    "        self.trans =transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path_x + self.X_train[index])\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize((128,128))\n",
    "        img = self.trans(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathtrain = \"face_image/\"\n",
    "train_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "dset_train = MakeData(pathtrain,pathtrain,train_transform,tr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dset_train,\n",
    "                          batch_size=64,\n",
    "                          shuffle=True,\n",
    "                          num_workers=1, # 1 for CUDA\n",
    "                          pin_memory=True # CUDA only\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "num_epochs = 150 # total amount of full passes over training data\n",
    "batch_size = 32\n",
    "train_loss=[]\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.train(True) \n",
    "    i=0\n",
    "    for X_batch in train_loader:\n",
    "        # train on batch\n",
    "        if args.cuda:\n",
    "            X_batch = Variable(X_batch.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(X_batch)\n",
    "        loss = loss_function(recon_batch, X_batch, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.cpu().data.numpy()[0])\n",
    "        i+=1\n",
    "        if(i%100==0):\n",
    "            print(np.mean(train_loss[-1]))\n",
    "        del loss\n",
    "    torch.save(model,'model')\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(train_loss[- 202000// batch_size :])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
